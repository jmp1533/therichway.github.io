import os
import datetime
import pytz
import yfinance as yf
import google.generativeai as genai
import requests
import re

# --- [í™˜ê²½ë³€ìˆ˜ ë° ì„¤ì •] ---
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
FOCUS_TOPIC = os.environ.get("FOCUS_TOPIC", "ë¯¸êµ­ ì¦ì‹œ ì‹œí™©")
SEOUL_TZ = pytz.timezone('Asia/Seoul')

# [ë””ìŠ¤í´ë ˆì´ë¨¸: ì‘ì€ ê¸€ì”¨ë¡œ í•˜ë‹¨ì— ë¶€ì°©ë  ë¬¸êµ¬]
DISCLAIMER_TEXT = """
<br><br>
<hr>
<p style="text-align: center; font-size: 0.9em; color: #888; line-height: 1.6;">
    <strong>[ì•ˆë‚´ ë° ë©´ì±… ì¡°í•­]</strong><br>
    ë³¸ ì½˜í…ì¸ ëŠ” ì¸ê³µì§€ëŠ¥(AI) ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.<br>
    íˆ¬ìì˜ ì±…ì„ì€ ì „ì ìœ¼ë¡œ íˆ¬ìì ë³¸ì¸ì—ê²Œ ìˆìœ¼ë©°, ì œê³µëœ ë°ì´í„°ëŠ” ì¼ë¶€ ì§€ì—°ë˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>
    ë‚´ìš©ì— ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ê±°ë‚˜ ì €ì‘ê¶Œ ë¬¸ì œê°€ ë°œìƒí•  ê²½ìš°, ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜ ì£¼ì‹œë©´ ì¦‰ì‹œ ìˆ˜ì • ë˜ëŠ” ì‚­ì œ ì¡°ì¹˜í•˜ê² ìŠµë‹ˆë‹¤.
</p>
<hr>
"""

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

def get_market_data():
    """ë°ì´í„° ìˆ˜ì§‘ ë¡œì§"""
    tickers = {"^DJI": "ë‹¤ìš°ì¡´ìŠ¤", "^GSPC": "S&P500", "^IXIC": "ë‚˜ìŠ¤ë‹¥", "^VIX": "ê³µí¬ì§€ìˆ˜"}
    data_str = "Recent Market Data (7 Days):\n"
    for symbol, name in tickers.items():
        try:
            ticker = yf.Ticker(symbol)
            hist = ticker.history(period="7d")
            if not hist.empty and len(hist) >= 2:
                close = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2]
                change = ((close - prev) / prev) * 100
                data_str += f"- {name}: {close:.2f} ({change:+.2f}%)\n"
        except: continue
    return data_str

def get_gemini_model():
    """ìµœì‹  ëª¨ë¸ ìš°ì„  ì„ íƒ ë¡œì§"""
    models = ['gemini-flash-latest', 'gemini-3-pro-preview', 'gemini-3-flash-preview', 'gemini-2.5-pro', 'gemini-2.5-flash-lite']
    for m in models:
        try:
            model = genai.GenerativeModel(m)
            model.generate_content("test", generation_config={"max_output_tokens": 1})
            return model
        except: continue
    return None

def generate_blog_post(market_data):
    if not GEMINI_API_KEY: return "Error: API Key missing."

    model = get_gemini_model()
    if not model: return "Error: No available models."

    now = datetime.datetime.now(SEOUL_TZ)
    date_str = now.strftime('%Y-%m-%d %H:%M:%S')
    weekday = now.weekday() # 0:ì›”, 1:í™”, ... 6:ì¼

    if weekday == 0:
        analysis_target = "ì§€ë‚œ ì£¼ë§(í† /ì¼) ì´ìŠˆ ë° ê¸ˆìš”ì¼ ë§ˆê° ì‹œí™© ë¶„ì„"
    elif 1 <= weekday <= 4:
        analysis_target = "ì „ì¼(ì–´ì œ) ì‹œì¥ ë° ë°¤ì‚¬ì´ ë¯¸êµ­ ì¦ì‹œ ë¶„ì„"
    else:
        analysis_target = "ìµœê·¼ ë§ˆê° ì‹œì¥ ë¶„ì„"

    # ---------------------------------------------------------
    # [Step 1] í”„ë¡¬í”„íŠ¸ ê³ ë„í™” (ë‹¤ì¤‘ ì†ŒìŠ¤ ë¶„ì„ + ë¶„ëŸ‰ í™•ëŒ€)
    # ---------------------------------------------------------
    prompt_analyst = f"""
    [Identity & Persona]
    You are a **World-class Global Economic Analyst and Blogger**. You have a deep understanding of financial markets and the ability to synthesize information from a wide array of sources. Your writing is insightful, balanced, and provides a multi-perspective view.

    [Task]
    Write a **very comprehensive and in-depth** blog post on "{FOCUS_TOPIC}". Your analysis must be based on a synthesis of information from the following premier news sources. You should demonstrate your expertise by cross-referencing different viewpoints and data points from them.

    [News Sources for Analysis]
    **US Sources (10):**
    - The Wall Street Journal
    - Bloomberg
    - Reuters
    - CNBC
    - The New York Times
    - The Financial Times
    - Associated Press (AP)
    - Fox Business
    - MarketWatch
    - Yahoo Finance

    **Korean Sources (10):**
    - í•œêµ­ê²½ì œ (Korea Economic Daily)
    - ë§¤ì¼ê²½ì œ (Maeil Business Newspaper)
    - ì¡°ì„ ì¼ë³´ (Chosun Ilbo)
    - ì¤‘ì•™ì¼ë³´ (JoongAng Ilbo)
    - ë™ì•„ì¼ë³´ (Donga Ilbo)
    - ì—°í•©ë‰´ìŠ¤ (Yonhap News)
    - YTN
    - SBS Biz
    - ë¨¸ë‹ˆíˆ¬ë°ì´ (Money Today)
    - ë„¤ì´ë²„ ì¦ê¶Œ (Naver Finance)

    [Context]
    - Today: {date_str} (Korea Time)
    - **Analysis Target**: {analysis_target}
    - Input Market Data: {market_data}

    [Requirements]
    1. **Length & Depth (CRITICAL)**:
       - The post must be **extremely detailed**, aiming for **4,000 to 5,000 characters** (excluding spaces).
       - Do not just summarize; provide deep context, historical comparisons, and future implications.
       - Each section should be substantial. For example, when discussing a sector, explain *why* it moved, which specific companies led the move, and what analysts are saying.
    2. **Multi-perspective Analysis**:
       - Do not just list news. Synthesize the information.
       - For a key issue, you might write something like: "While US media like The Wall Street Journal focused on the Fed's inflation concerns, Korean outlets such as ë§¤ì¼ê²½ì œ highlighted the impact on the won-dollar exchange rate for exporters."
       - Show that you have considered views from both US and Korean perspectives.
    3. **Structure & Headings**:
       - Use engaging Korean subheadings. DO NOT use "Market Pulse", "Deep Dive", etc.
       - Create a logical flow: Introduction -> Broad Market Overview -> Deep Dive into 3-4 Key Themes (with multi-source analysis) -> Outlook & Strategy.
    4. **Visuals**:
       - Include a Markdown Table for key data.
       - Include one Mermaid chart to illustrate a key concept or trend.
    5. **References (CRITICAL)**:
       - Title: "## ğŸ“š ì£¼ìš” ì°¸ê³  ë‰´ìŠ¤"
       - **Generate a list of 5-7 key news articles** that you theoretically used for your analysis.
       - **The URLs must be plausible and point to the correct news domain.** For example, a Wall Street Journal link should start with `https://www.wsj.com/`.
       - **This is a test of your ability to generate realistic, relevant links based on the day's news.** Do not invent fake news, but find plausible real news headlines and construct URLs.
    6. **Tags**:
       - Title: "### ğŸ·ï¸ íƒœê·¸"
       - Generate 5 relevant hashtags.

    [Language]: Korean (Professional, High-quality, Analytical).
    """

    draft = ""
    try:
        draft = model.generate_content(prompt_analyst).text
    except Exception as e:
        return f"Error in Step 1: {str(e)}"

    # ---------------------------------------------------------
    # [Step 2] í¸ì§‘ì¥ ëª¨ë“œ
    # ---------------------------------------------------------
    prompt_editor = f"""
    [Role] Chief Editor
    [Input Draft]
    {draft}

    [Task] Final Polish.
    1. **Length Check**: Ensure the content is substantial (aiming for 4000-5000 chars). If it feels short, expand on the analysis.
    2. **Link Check**: Ensure ALL links are plausible and direct to the correct domain.
    3. **Formatting**: Ensure Tables/Mermaid are correct.
    4. **Tone Check**: Ensure it sounds like a professional economic blog.
    5. **Header Check**: Ensure NO generic headers like "Market Pulse" exist.
    6. **Front Matter**:
    ---
    layout: single
    title: "YOUR_CATCHY_TITLE_BASED_ON_CONTENT"
    date: {date_str}
    categories: ["ê²½ì œÂ·ì¬í…Œí¬", "ë¯¸êµ­ì¦ì‹œ"]
    published: true
    toc: true
    ---

    [Output] Return ONLY the final Markdown content.
    """

    try:
        final_response = model.generate_content(prompt_editor).text
        content = final_response.strip()

        if content.startswith("```markdown"): content = content.replace("```markdown", "", 1)
        if content.startswith("```"): content = content.replace("```", "", 1)
        if content.endswith("```"): content = content[:-3]

        return content.strip() + DISCLAIMER_TEXT

    except Exception as e:
        return f"Error in Step 2: {str(e)}"

def save_and_notify(content):
    if "Error" in content:
        print(f"âŒ [API Error] {content}")
        return

    today = datetime.datetime.now(SEOUL_TZ).strftime("%Y-%m-%d")
    timestamp = datetime.datetime.now(SEOUL_TZ).strftime("%H%M")

    category_dir = "_posts/us-stock"
    os.makedirs(category_dir, exist_ok=True)

    filename = f"{today}-market-{timestamp}.md"
    filepath = f"{category_dir}/{filename}"

    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"âœ… í¬ìŠ¤íŒ… íŒŒì¼ ìƒì„± ì™„ë£Œ: {filepath}")

    if TELEGRAM_TOKEN and TELEGRAM_CHAT_ID:
        title_match = re.search(r'title:\s*"(.*?)"', content)
        post_title = title_match.group(1) if title_match else "ì œëª© ì—†ìŒ"

        msg = (
            f"[ë¯¸êµ­ ì¦ì‹œ ë¦¬í¬íŠ¸ ìƒì„±]\n"
            f"{post_title}\n\n"
            f"/publish"
        )

        try:
            api_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            response = requests.post(
                api_url,
                json={"chat_id": TELEGRAM_CHAT_ID, "text": msg}
            )
            if response.status_code == 200:
                print("âœ… í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
            else:
                print(f"âŒ í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {response.text}")
        except Exception as e:
            print(f"âŒ í…”ë ˆê·¸ë¨ ì—°ê²° ì—ëŸ¬: {e}")

if __name__ == "__main__":
    market_data = get_market_data()
    post = generate_blog_post(market_data)
    save_and_notify(post)